# -*- coding: utf-8 -*-
"""SVC_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qo_lUTnQ4M1GKWmEhzebf67SGWUynM6p
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from zipfile import ZipFile
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

from sklearn.svm import SVC

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, confusion_matrix, roc_auc_score, RocCurveDisplay
)

zip_path = "/content/online+shoppers+purchasing+intention+dataset (1).zip"   # CHANGE to your actual filename

with ZipFile(zip_path, 'r') as z:
    z.extractall("/content/")

import os
os.listdir("/content/")

df = pd.read_csv("/content/online_shoppers_intention.csv")  # change if needed
df.head()

df = df.copy()

# Identify categorical & numerical columns
cat_cols = df.select_dtypes(include=['object', 'bool']).columns
num_cols = df.select_dtypes(include=['float64', 'int64']).columns

# Label encode categorical variables
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

# Separate features and labels
X = df.drop("Revenue", axis=1)
y = df["Revenue"]

# Standardize numeric columns
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X, y)

print("Before SMOTE:", y.value_counts())
print("After SMOTE:", y_resampled.value_counts())

X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled,
    test_size=0.20,
    random_state=42,
    stratify=y_resampled
)

probability=True

svc_rbf = SVC(
    kernel='rbf',
    C=1.0,
    gamma='scale',
    probability=True,
    random_state=42
)

svc_rbf.fit(X_train, y_train)

svc_poly = SVC(
    kernel='poly',
    degree=3,
    C=1.0,
    gamma='scale',
    probability=True,
    random_state=42
)

svc_poly.fit(X_train, y_train)

def evaluate_model(model, X_test, y_test, title="Model"):
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc = roc_auc_score(y_test, y_proba)

    print(f"=== {title} ===")
    print("Accuracy:", acc)
    print("Precision:", prec)
    print("Recall:", rec)
    print("F1 Score:", f1)
    print("ROC AUC:", roc)
    print("------------------------")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
    plt.title(f"Confusion Matrix - {title}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    # ROC Curve
    RocCurveDisplay.from_predictions(y_test, y_proba)
    plt.title(f"ROC Curve - {title}")
    plt.show()

evaluate_model(svc_rbf, X_test, y_test, title="SVC (RBF Kernel)")

evaluate_model(svc_poly, X_test, y_test, title="SVC (Polynomial Kernel)")

def evaluate_model(model, X_test, y_test, title="Model"):
    print(f"================= {title} =================")

    # Predictions
    y_pred = model.predict(X_test)

    # Try probabilities (for ROC); if fails â†’ fallback
    try:
        y_proba = model.predict_proba(X_test)[:, 1]
        roc = roc_auc_score(y_test, y_proba)
    except:
        y_proba = None
        roc = None

    # Metrics
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)

    # Print all metrics clearly
    print("Accuracy :", acc)
    print("Precision:", prec)
    print("Recall   :", rec)
    print("F1 Score :", f1)
    print("ROC AUC  :", roc if roc is not None else "ROC unavailable (no probability output)")
    print("---------------------------------------")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {title}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    # ROC Curve (only if probabilities exist)
    if y_proba is not None:
        RocCurveDisplay.from_predictions(y_test, y_proba)
        plt.title(f"ROC Curve - {title}")
        plt.show()
    else:
        print("ROC Curve could not be generated (model did not output probabilities).")

