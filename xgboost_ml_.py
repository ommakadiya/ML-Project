# -*- coding: utf-8 -*-
"""XGBoost_ml .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/116Rpn4fYfEkEMuG0ueOQFEe_jUBfFCi1
"""

# pip install xgboost scikit-learn imbalanced-learn pandas numpy matplotlib seaborn
# Uncomment the line above and run in terminal: pip install xgboost scikit-learn imbalanced-learn pandas numpy matplotlib seaborn

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, RocCurveDisplay
)
import seaborn as sns
import matplotlib.pyplot as plt
import xgboost as xgb

from zipfile import ZipFile

zip_path = "/content/online+shoppers+purchasing+intention+dataset (1).zip"   # <- change filename if needed
with ZipFile(zip_path, 'r') as z:
    z.extractall("/content/")

# Confirm extracted files
import os
os.listdir("/content/")

df = pd.read_csv("/content/online_shoppers_intention.csv")  # adjust filename
df.head()

df = df.copy()

# Identify categorical & numeric columns
cat_cols = df.select_dtypes(include=['object', 'bool']).columns
num_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Encode categorical features
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

# Separate features and target
X = df.drop("Revenue", axis=1)
y = df["Revenue"]

# Standardization
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X, y)

print("Before SMOTE:", y.value_counts())
print("After SMOTE:", y_resampled.value_counts())

X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled,
    test_size=0.20,
    random_state=42,
    stratify=y_resampled
)

model = xgb.XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.9,
    colsample_bytree=0.9,
    random_state=42,
    eval_metric="logloss"
)

model.fit(X_train, y_train)

y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred)
rec = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc = roc_auc_score(y_test, y_proba)

print("Accuracy:", acc)
print("Precision:", prec)
print("Recall:", rec)
print("F1 Score:", f1)
print("ROC AUC:", roc)

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

RocCurveDisplay.from_predictions(y_test, y_proba)
plt.title("ROC Curve - XGBoost")
plt.show()

xgb.plot_importance(model, max_num_features=20)
plt.show()



